{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "knowing-medium",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "dietary-intake",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2994, -0.4063,  0.6299,  ..., -0.1464,  0.4849, -0.6689],\n",
      "        [ 0.0531,  0.4342, -0.8415,  ..., -0.2010,  1.5560,  0.7890],\n",
      "        [ 0.6613,  0.6196, -2.6043,  ...,  0.1770,  0.9331,  0.4427]])\n",
      "(tensor([4, 4, 4, 5, 5, 5, 6, 6, 6, 7, 7, 7, 0, 0, 1, 1, 2, 2, 2, 2, 4, 5, 6, 7,\n",
      "        8, 8, 4, 6, 7, 5, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 7, 8, 8,\n",
      "        8, 8, 8, 8]), tensor([5, 6, 7, 4, 6, 7, 4, 5, 7, 4, 5, 6, 1, 8, 0, 8, 4, 5, 6, 7, 2, 2, 2, 2,\n",
      "        0, 1, 6, 4, 5, 7, 2, 3, 4, 5, 6, 7, 2, 3, 4, 5, 6, 7, 0, 1, 3, 8, 0, 1,\n",
      "        2, 4, 5, 6, 7, 8, 0, 1, 3, 8, 0, 1, 3, 8, 0, 1, 3, 8, 0, 1, 3, 8, 2, 3,\n",
      "        4, 5, 6, 7]))\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3], dtype=torch.int32)\n",
      "tensor([0.3333, 0.3333, 0.3333, 0.3333, 0.3333, 0.3333, 0.3333, 0.3333, 0.3333,\n",
      "        0.3333, 0.3333, 0.3333, 0.5000, 0.5000, 0.5000, 0.5000, 0.2500, 0.2500,\n",
      "        0.2500, 0.2500, 1.0000, 1.0000, 1.0000, 1.0000, 0.5000, 0.5000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 0.1666, 0.1666, 0.1666, 0.1666, 0.1666, 0.1666,\n",
      "        0.1666, 0.1666, 0.1666, 0.1666, 0.1666, 0.1666, 0.2500, 0.2500, 0.2500,\n",
      "        0.2500, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250,\n",
      "        0.2500, 0.2500, 0.2500, 0.2500, 0.2500, 0.2500, 0.2500, 0.2500, 0.2500,\n",
      "        0.2500, 0.2500, 0.2500, 0.2500, 0.2500, 0.2500, 0.2500, 0.1666, 0.1666,\n",
      "        0.1666, 0.1666, 0.1666, 0.1666], dtype=torch.float16)\n",
      "(tensor(79, dtype=torch.int32), tensor(79, dtype=torch.int32))\n",
      "(tensor(34, dtype=torch.int32), tensor(34, dtype=torch.int32))\n",
      "(tensor(100, dtype=torch.int32), tensor(102, dtype=torch.int32))\n",
      "(tensor(49, dtype=torch.int32), tensor(52, dtype=torch.int32))\n",
      "(tensor(8, dtype=torch.int32), tensor(10, dtype=torch.int32))\n",
      "(tensor(95, dtype=torch.int32), tensor(97, dtype=torch.int32))\n",
      "(tensor(18, dtype=torch.int32), tensor(18, dtype=torch.int32))\n",
      "(tensor(66, dtype=torch.int32), tensor(67, dtype=torch.int32))\n",
      "(tensor(26, dtype=torch.int32), tensor(26, dtype=torch.int32))\n"
     ]
    }
   ],
   "source": [
    "graphs, _ = dgl.load_graphs('/afs/inf.ed.ac.uk/user/s20/s2041332/mlp_project/graph/train_graphs_400.dgl')\n",
    "\n",
    "print(graphs[2].ndata['n_embed'][8])\n",
    "\n",
    "print(graphs[2].edges())\n",
    "print(graphs[2].edata['rel_type'])\n",
    "print(graphs[2].edata['e_weight'])\n",
    "\n",
    "for i in zip(graphs[2].ndata['loc_start'],graphs[2].ndata['loc_end']):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "decent-telescope",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 2])\n",
      "torch.Size([3, 2])\n",
      "tensor([[[0., 1.],\n",
      "         [1., 2.],\n",
      "         [2., 3.]],\n",
      "\n",
      "        [[3., 4.],\n",
      "         [4., 5.],\n",
      "         [5., 6.]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1.5000, 2.5000],\n",
       "        [1.0000, 2.0000],\n",
       "        [5.0000, 6.0000]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([[[0, 1], [1, 2], [2, 3]],\n",
    "                  [[3,4],[4,5],[5,6]]],dtype=torch.float)\n",
    "print(a.shape)\n",
    "print(a.mean(0).shape)\n",
    "\n",
    "print(a)\n",
    "\n",
    "torch.stack([a.mean(0)[0], a[0][1], a[-1][2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "supposed-shuttle",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/afs/inf.ed.ac.uk/user/s20/s2041332/miniconda3/envs/mlp_env/lib/python3.6/site-packages/dgl/base.py:45: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.\n",
      "  return warnings.warn(message, category=category, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [2., 2., 2., 2.]]), tensor([[0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [2., 2., 2., 2.]])]\n",
      "torch.Size([2, 2, 3, 3])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (6x7 and 4x3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-d2435b421681>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_norm_adj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mlp_project/v2/RGCNLayer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, h, norm_adj)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mupdate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmsg\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_hid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mgated_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_gate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0mgated_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgated_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mlp_env/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mlp_env/lib/python3.6/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mlp_env/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1690\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1692\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1693\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (6x7 and 4x3)"
     ]
    }
   ],
   "source": [
    "from RGCNLayer import *\n",
    "import numpy as np\n",
    "import dgl\n",
    "\n",
    "in_feat = 4\n",
    "out_feat = 3\n",
    "num_rels = 2\n",
    "\n",
    "\n",
    "# Test data\n",
    "graphs = []\n",
    "for _ in range(2): \n",
    "    g = dgl.DGLGraph((np.random.randint(0, 3, (2,)), np.random.randint(0, 3, (2,))))\n",
    "    g.ndata['h'] = torch.randn(g.number_of_nodes(), in_feat)\n",
    "    g.edata['rel_type'] = torch.randint(0, num_rels, (2,))\n",
    "    g.edata['norm'] = torch.randn(2)\n",
    "    graphs.append(g)\n",
    "\n",
    "num_rels = 2\n",
    "max_nodes = 3\n",
    "\n",
    "\n",
    "def dgl2matrix(g):\n",
    "    edge_pair = g.edges()\n",
    "    us,vs = edge_pair\n",
    "    norm_adj = torch.zeros((num_rels, max_nodes, max_nodes))\n",
    "    for i,(u,v) in enumerate(zip(us, vs)):\n",
    "        norm_adj[g.edata['rel_type'][i]][u][v] = g.edata['e_weight'][i]\n",
    "    return norm_adj\n",
    "\n",
    "\n",
    "bg = []\n",
    "\n",
    "# Create two graphs with max nodes size\n",
    "g1 = dgl.DGLGraph()\n",
    "for n in range(max_nodes):\n",
    "    g1.add_nodes(1, data={'n_embed':torch.tensor([[n, n, n, n]],dtype=torch.float)})\n",
    "\n",
    "norm1 = torch.tensor([0.1, 0.1, 0.1, 0.1], dtype=torch.float)\n",
    "rel1 = torch.tensor([0, 1, 0, 1], dtype=torch.int)\n",
    "# g1: 0-1, 0-2\n",
    "g1.add_edges([0, 0, 1, 2], [1, 2, 0, 0], data={'e_weight': norm1, 'rel_type': rel1})\n",
    "adj1 = dgl.khop_adj(g1, 1)\n",
    "bg.append(g1)\n",
    "\n",
    "# g2: 1-2\n",
    "g2 = dgl.DGLGraph()\n",
    "for n in range(max_nodes):\n",
    "    g2.add_nodes(1, data={'n_embed':torch.tensor([[n, n, n, n]],dtype=torch.float)})\n",
    "\n",
    "norm2 = torch.tensor([0.2, 0.2], dtype=torch.float)\n",
    "rel2 = torch.tensor([0, 0], dtype=torch.int)\n",
    "g2.add_edges([1, 2], [2, 1], data={'e_weight': norm2, 'rel_type': rel2})\n",
    "adj2 = dgl.khop_adj(g2, 1)\n",
    "bg.append(g2)\n",
    "# print(g1.edata['e_weight'])\n",
    "\n",
    "\n",
    "b_h = []\n",
    "b_norm_adj = []\n",
    "for g in bg:\n",
    "    norm_adj = dgl2matrix(g)\n",
    "    h = g.ndata['n_embed']\n",
    "    b_h.append(h)\n",
    "    b_norm_adj.append(norm_adj)\n",
    "\n",
    "batch_size = 2\n",
    "layer = MyRGCNLayer(in_feat, out_feat, num_rels)\n",
    "\n",
    "print(b_h)\n",
    "# batch the input\n",
    "b_h = torch.stack(b_h)\n",
    "b_norm_adj = torch.stack(b_norm_adj)\n",
    "\n",
    "# print(\"(batch_size, num_rels, num_nodes, num_nodes):\",b_norm_adj.shape)\n",
    "# print(\"[batch_size, num_nodes, in_dim]:\", b_h.shape)\n",
    "\n",
    "# print(b_h)\n",
    "\n",
    "# b_h = b_h.expand(batch_size, 2, -1, -1)\n",
    "# print(\"after expand:\",b_h.shape)\n",
    "# print(b_h)\n",
    "\n",
    "\n",
    "out = layer.forward(b_h, b_norm_adj)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "arranged-funds",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from dgl import DGLGraph\n",
    "import dgl.function as fn\n",
    "from functools import partial\n",
    "\n",
    "from RGCNLayer import *\n",
    "\n",
    "class RGCNLayer(nn.Module):\n",
    "    def __init__(self, in_feat, out_feat, num_rels, num_bases=-1, bias=None,\n",
    "                 activation=None, is_input_layer=False):\n",
    "        super(RGCNLayer, self).__init__()\n",
    "        self.in_feat = in_feat\n",
    "        self.out_feat = out_feat\n",
    "        self.num_rels = num_rels\n",
    "        self.num_bases = num_bases\n",
    "        self.bias = bias\n",
    "        self.activation = activation\n",
    "        self.is_input_layer = is_input_layer\n",
    "\n",
    "        # sanity check\n",
    "        if self.num_bases <= 0 or self.num_bases > self.num_rels:\n",
    "            self.num_bases = self.num_rels\n",
    "\n",
    "        # weight bases in equation (3)\n",
    "        self.weight = nn.Parameter(torch.Tensor(self.num_bases, self.in_feat,\n",
    "                                                self.out_feat))\n",
    "        if self.num_bases < self.num_rels:\n",
    "            # linear combination coefficients in equation (3)\n",
    "            self.w_comp = nn.Parameter(torch.Tensor(self.num_rels, self.num_bases))\n",
    "\n",
    "        # add bias\n",
    "        if self.bias:\n",
    "            self.bias = nn.Parameter(torch.Tensor(out_feat))\n",
    "\n",
    "        # init trainable parameters\n",
    "        nn.init.xavier_uniform_(self.weight,\n",
    "                                gain=nn.init.calculate_gain('relu'))\n",
    "        if self.num_bases < self.num_rels:\n",
    "            nn.init.xavier_uniform_(self.w_comp,\n",
    "                                    gain=nn.init.calculate_gain('relu'))\n",
    "        if self.bias:\n",
    "            nn.init.xavier_uniform_(self.bias,\n",
    "                                    gain=nn.init.calculate_gain('relu'))\n",
    "\n",
    "    def forward(self, g):\n",
    "        if self.num_bases < self.num_rels:\n",
    "            # generate all weights from bases (equation (3))\n",
    "            weight = self.weight.view(self.in_feat, self.num_bases, self.out_feat)\n",
    "            weight = torch.matmul(self.w_comp, weight).view(self.num_rels,\n",
    "                                                        self.in_feat, self.out_feat)\n",
    "        else:\n",
    "            weight = self.weight\n",
    "\n",
    "        if self.is_input_layer:\n",
    "            def message_func(edges):\n",
    "                # for input layer, matrix multiply can be converted to be\n",
    "                # an embedding lookup using source node id\n",
    "                embed = weight.view(-1, self.out_feat)\n",
    "                index = edges.data['rel_type'] * self.in_feat + edges.src['id']\n",
    "                return {'msg': embed[index] * edges.data['norm']}\n",
    "        else:\n",
    "            def message_func(edges):\n",
    "                w = weight[edges.data['rel_type']]\n",
    "                msg = torch.bmm(edges.src['h'].unsqueeze(1), w).squeeze()\n",
    "                msg = msg * edges.data['norm']\n",
    "                return {'msg': msg}\n",
    "\n",
    "        def apply_func(nodes):\n",
    "            h = nodes.data['h']\n",
    "            if self.bias:\n",
    "                h = h + self.bias\n",
    "            if self.activation:\n",
    "                h = self.activation(h)\n",
    "            return {'h': h}\n",
    "\n",
    "        g.update_all(message_func, fn.sum(msg='msg', out='h'), apply_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charged-premium",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, num_nodes, h_dim, out_dim, num_rels,\n",
    "                 num_bases=-1, num_hidden_layers=1):\n",
    "        super(Model, self).__init__()\n",
    "        self.num_nodes = num_nodes\n",
    "        self.h_dim = h_dim\n",
    "        self.out_dim = out_dim\n",
    "        self.num_rels = num_rels\n",
    "        self.num_bases = num_bases\n",
    "        self.num_hidden_layers = num_hidden_layers\n",
    "\n",
    "        # create rgcn layers\n",
    "        self.build_model()\n",
    "\n",
    "        # create initial features\n",
    "        self.features = self.create_features()\n",
    "\n",
    "    def build_model(self):\n",
    "        self.layers = nn.ModuleList()\n",
    "        # input to hidden\n",
    "        i2h = self.build_input_layer()\n",
    "        self.layers.append(i2h)\n",
    "        # hidden to hidden\n",
    "        for _ in range(self.num_hidden_layers):\n",
    "            h2h = self.build_hidden_layer()\n",
    "            self.layers.append(h2h)\n",
    "        # hidden to output\n",
    "        h2o = self.build_output_layer()\n",
    "        self.layers.append(h2o)\n",
    "\n",
    "    # initialize feature for each node\n",
    "    def create_features(self):\n",
    "        features = torch.arange(self.num_nodes)\n",
    "        return features\n",
    "\n",
    "    def build_input_layer(self):\n",
    "        return RGCNLayer(self.num_nodes, self.h_dim, self.num_rels, self.num_bases,\n",
    "                         activation=F.relu, is_input_layer=True)\n",
    "\n",
    "    def build_hidden_layer(self):\n",
    "        return RGCNLayer(self.h_dim, self.h_dim, self.num_rels, self.num_bases,\n",
    "                         activation=F.relu)\n",
    "\n",
    "    def build_output_layer(self):\n",
    "        return RGCNLayer(self.h_dim, self.out_dim, self.num_rels, self.num_bases,\n",
    "                         activation=partial(F.softmax, dim=1))\n",
    "\n",
    "    def forward(self, g):\n",
    "        if self.features is not None:\n",
    "            g.ndata['id'] = self.features\n",
    "        for layer in self.layers:\n",
    "            layer(g)\n",
    "        return g.ndata.pop('h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "judicial-gibraltar",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load graph data\n",
    "from dgl.contrib.data import load_data\n",
    "import numpy as np\n",
    "data = load_data(dataset='aifb')\n",
    "num_nodes = data.num_nodes\n",
    "num_rels = data.num_rels\n",
    "num_classes = data.num_classes\n",
    "labels = data.labels\n",
    "train_idx = data.train_idx\n",
    "# split training and validation set\n",
    "val_idx = train_idx[:len(train_idx) // 5]\n",
    "train_idx = train_idx[len(train_idx) // 5:]\n",
    "\n",
    "# edge type and normalization factor\n",
    "edge_type = torch.from_numpy(data.edge_type)\n",
    "edge_norm = torch.from_numpy(data.edge_norm).unsqueeze(1)\n",
    "\n",
    "labels = torch.from_numpy(labels).view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sweet-estate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configurations\n",
    "n_hidden = 16 # number of hidden units\n",
    "n_bases = -1 # use number of relations as number of bases\n",
    "n_hidden_layers = 0 # use 1 input layer, 1 output layer, no hidden layer\n",
    "n_epochs = 25 # epochs to train\n",
    "lr = 0.01 # learning rate\n",
    "l2norm = 0 # L2 norm coefficient\n",
    "\n",
    "# create graph\n",
    "g = DGLGraph()\n",
    "g.add_nodes(num_nodes)\n",
    "g.add_edges(data.edge_src, data.edge_dst)\n",
    "g.edata.update({'rel_type': edge_type, 'norm': edge_norm})\n",
    "\n",
    "# create model\n",
    "model = Model(len(g),\n",
    "              n_hidden,\n",
    "              num_classes,\n",
    "              num_rels,\n",
    "              num_bases=n_bases,\n",
    "              num_hidden_layers=n_hidden_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "twenty-investment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=l2norm)\n",
    "\n",
    "print(\"start training...\")\n",
    "model.train()\n",
    "for epoch in range(n_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    logits = model.forward(g)\n",
    "    loss = F.cross_entropy(logits[train_idx], labels[train_idx])\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    train_acc = torch.sum(logits[train_idx].argmax(dim=1) == labels[train_idx])\n",
    "    train_acc = train_acc.item() / len(train_idx)\n",
    "    val_loss = F.cross_entropy(logits[val_idx], labels[val_idx])\n",
    "    val_acc = torch.sum(logits[val_idx].argmax(dim=1) == labels[val_idx])\n",
    "    val_acc = val_acc.item() / len(val_idx)\n",
    "    print(\"Epoch {:05d} | \".format(epoch) +\n",
    "          \"Train Accuracy: {:.4f} | Train Loss: {:.4f} | \".format(\n",
    "              train_acc, loss.item()) +\n",
    "          \"Validation Accuracy: {:.4f} | Validation loss: {:.4f}\".format(\n",
    "              val_acc, val_loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "connected-source",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "matched-directory",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "after-scope",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recovered-miniature",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
